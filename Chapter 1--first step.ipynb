{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch-tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6741e+22, 4.6304e+27, 7.2151e+22, 1.7836e+31],\n",
       "        [1.3563e-19, 1.3563e-19, 6.1083e-04, 4.6162e+24],\n",
       "        [6.9840e+31, 1.2694e+36, 7.2443e+22, 1.1022e+24],\n",
       "        [7.2734e+22, 4.7429e+30, 1.0555e+18, 4.7294e+22],\n",
       "        [1.7749e+28, 7.2065e+31, 6.8524e+16, 4.8409e+25]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7647, 0.6399, 0.0046, 0.0609],\n",
       "        [0.1106, 0.7692, 0.1075, 0.9520],\n",
       "        [0.5310, 0.5174, 0.8417, 0.6709],\n",
       "        [0.4656, 0.8683, 0.4163, 0.7799],\n",
       "        [0.3758, 0.9058, 0.2126, 0.3041]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand(5,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两种加法 add与add_，带_会改变原来的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2949, 1.1085, 0.9185, 0.4804],\n",
       "        [1.1030, 1.4496, 0.9173, 1.8425],\n",
       "        [0.9404, 1.3971, 1.2985, 0.8877],\n",
       "        [1.0070, 1.8347, 1.1618, 1.1811],\n",
       "        [1.2959, 1.4801, 0.6838, 1.2320]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7647, 0.6399, 0.0046, 0.0609],\n",
       "        [0.1106, 0.7692, 0.1075, 0.9520],\n",
       "        [0.5310, 0.5174, 0.8417, 0.6709],\n",
       "        [0.4656, 0.8683, 0.4163, 0.7799],\n",
       "        [0.3758, 0.9058, 0.2126, 0.3041]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2949, 1.1085, 0.9185, 0.4804],\n",
       "        [1.1030, 1.4496, 0.9173, 1.8425],\n",
       "        [0.9404, 1.3971, 1.2985, 0.8877],\n",
       "        [1.0070, 1.8347, 1.1618, 1.1811],\n",
       "        [1.2959, 1.4801, 0.6838, 1.2320]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2949, 1.1085, 0.9185, 0.4804],\n",
       "        [1.1030, 1.4496, 0.9173, 1.8425],\n",
       "        [0.9404, 1.3971, 1.2985, 0.8877],\n",
       "        [1.0070, 1.8347, 1.1618, 1.1811],\n",
       "        [1.2959, 1.4801, 0.6838, 1.2320]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy与torch之间的互相转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.numpy()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor与numpy共享内存，一个改变，另一个也会改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_(1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor可以通过 .cuda 转为GPU的Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x+y\n",
    "    print(\"gpu is valiable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autograd模块实现了自动微分功能，Variable是其中的核心，Variable封装了Tensor，其主要包含三个属性：\n",
    "\n",
    "data：保存Variable所包含的Tensor\n",
    "\n",
    "grad：保存data的梯度，是一个累加量，Variable类型\n",
    "\n",
    "grad_fn：指向一个function对象，用来反向传播梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(2,2), requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x7fca443d5940>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于是sum，梯度为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反向传播的梯度是累加的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.data.zero_() #将梯度置0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable与Tensor之间的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Variable(x, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == y.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn是为神经网络设计的模块化接口，建立在Autograd之上。nn.Module是nn最重要的类，可看作网络的封装，包含网络各层定义和forward方法，调用forward方(input)方法，可以实现前向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义网络时，需要继承nn.Module，并实现它的forward方法，把网络中的可学习参数放到构造函数__init__中。若某一层（如Relu）不具有可学习参数，则放不放都可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) #分别代表in_channel,out_channel,kernel_size\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120) #full connection layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x): #注意forward有输入，在nn.Module的子类中定义了forward类后，backward函数就会利用Autograd自动实现\n",
    "        #print(\"init x size:\", x.size())\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        #print(\"after 1 conv:\", x.size())\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        #print(\"after 2 convs:\",x.size())\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net) #输出的为__init__中的内容\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络的可学习参数通过nn.parameters()返回，nn.named_parameters()可同时返回可学习参数及名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fca443c8150>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.0220,  0.0009, -0.1558, -0.1124, -0.0535],\n",
      "          [-0.0823, -0.0141, -0.0129, -0.0793, -0.0659],\n",
      "          [ 0.0085,  0.1019, -0.0991,  0.0689,  0.0124],\n",
      "          [-0.1334,  0.0619,  0.1996,  0.1182, -0.0153],\n",
      "          [ 0.0085, -0.1369, -0.1661,  0.0244,  0.0414]]],\n",
      "\n",
      "\n",
      "        [[[-0.1188,  0.1376, -0.1233, -0.0572,  0.0400],\n",
      "          [-0.1948,  0.1635,  0.0753, -0.0559, -0.0668],\n",
      "          [ 0.0632, -0.1845, -0.1019, -0.0094,  0.0455],\n",
      "          [ 0.1072,  0.0713, -0.0613, -0.0196,  0.1300],\n",
      "          [-0.0907, -0.0052,  0.0843, -0.1475, -0.0078]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0845,  0.0212, -0.1848, -0.1424, -0.1535],\n",
      "          [ 0.0519, -0.0954, -0.1276,  0.1531,  0.0762],\n",
      "          [ 0.0376, -0.1507,  0.1321,  0.0859,  0.0204],\n",
      "          [ 0.0223, -0.0475, -0.0053, -0.0432, -0.0968],\n",
      "          [-0.1269, -0.1678, -0.1642, -0.0275,  0.0557]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0027, -0.1525, -0.1283, -0.1185, -0.1477],\n",
      "          [-0.1468,  0.0683, -0.0982,  0.1251,  0.1538],\n",
      "          [ 0.0907, -0.1952, -0.1734,  0.0111, -0.1415],\n",
      "          [-0.0142,  0.1180, -0.0953, -0.0738, -0.0311],\n",
      "          [ 0.0196,  0.1404,  0.1328,  0.1597, -0.1059]]],\n",
      "\n",
      "\n",
      "        [[[-0.1738, -0.1975, -0.0166,  0.0247,  0.0164],\n",
      "          [-0.1009, -0.1069,  0.1273,  0.1774,  0.1773],\n",
      "          [-0.1429, -0.1452,  0.0505, -0.1884, -0.0890],\n",
      "          [-0.0404, -0.0300, -0.0414,  0.0254,  0.0426],\n",
      "          [-0.0518,  0.1768,  0.1542, -0.1279, -0.0699]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0501, -0.0532, -0.0277,  0.1451, -0.1422],\n",
      "          [ 0.0062, -0.1526, -0.0782,  0.1087,  0.1826],\n",
      "          [-0.1081, -0.0912, -0.0561,  0.0804, -0.0313],\n",
      "          [ 0.0119,  0.0364,  0.1104, -0.1723, -0.1260],\n",
      "          [-0.1987, -0.0877, -0.1529,  0.1078, -0.0141]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1877, -0.0226, -0.1901, -0.1023,  0.0118,  0.0942],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-7.9987e-02,  3.1013e-02, -5.3930e-02,  1.6201e-02, -5.7990e-03],\n",
      "          [-1.4480e-02,  1.1639e-02, -2.5376e-02, -5.6889e-02, -7.5401e-03],\n",
      "          [-4.6570e-02,  7.3102e-02,  6.8098e-02,  5.1004e-02,  6.1515e-02],\n",
      "          [-8.8941e-03, -6.9200e-02, -7.5796e-02, -2.5254e-02, -5.8582e-02],\n",
      "          [ 7.8844e-02,  6.9835e-02,  7.9474e-02,  1.8853e-02, -5.3320e-02]],\n",
      "\n",
      "         [[-7.2866e-03, -6.3063e-02,  3.6746e-02,  6.6631e-02,  2.2597e-02],\n",
      "          [ 9.0562e-03, -2.5655e-02,  4.2099e-02, -6.8506e-02,  7.0840e-02],\n",
      "          [ 1.6133e-02,  5.8269e-02, -5.1714e-02, -5.7020e-02,  1.0880e-02],\n",
      "          [-4.4587e-02,  1.2514e-03, -5.4681e-02, -2.9818e-02,  6.2259e-02],\n",
      "          [ 2.7631e-02, -4.1617e-03, -6.9159e-02, -2.1424e-02,  7.1593e-02]],\n",
      "\n",
      "         [[-2.9825e-02, -5.3983e-02,  2.6131e-02,  7.3983e-02, -4.5494e-02],\n",
      "          [-6.7694e-02, -5.1560e-02,  1.6307e-02,  9.1445e-04,  3.4239e-02],\n",
      "          [ 6.6989e-02,  3.8864e-02, -8.0985e-02,  7.6647e-02,  2.0456e-02],\n",
      "          [-4.3731e-02,  1.6411e-02, -5.4072e-02,  3.7304e-02, -3.3253e-02],\n",
      "          [ 6.6728e-02, -7.4634e-02,  4.9301e-02, -6.2067e-02, -5.3457e-02]],\n",
      "\n",
      "         [[ 8.9147e-03, -8.0406e-02,  1.5105e-02, -8.0776e-02,  3.0394e-03],\n",
      "          [ 7.4430e-02, -3.2772e-03,  6.6961e-02, -2.4694e-02, -8.7167e-03],\n",
      "          [-3.4373e-02, -2.7148e-02,  2.3102e-02,  2.5195e-03, -2.1883e-02],\n",
      "          [-1.4940e-02, -7.7870e-02, -5.6186e-02,  5.9812e-02,  6.2030e-02],\n",
      "          [ 6.7261e-02, -7.8482e-02,  7.9854e-02, -8.0656e-02,  2.2557e-02]],\n",
      "\n",
      "         [[ 4.3164e-02,  4.7169e-02, -5.3286e-02, -2.4808e-02, -1.8846e-02],\n",
      "          [-1.0286e-03,  7.1630e-02, -5.8873e-02,  1.5406e-02, -9.9293e-03],\n",
      "          [-2.9610e-02, -3.3590e-02, -2.8064e-02, -3.4648e-02, -3.5033e-02],\n",
      "          [-7.2602e-02,  2.0758e-02,  7.2652e-02,  1.1607e-02,  4.3378e-02],\n",
      "          [-4.9588e-02, -2.5276e-02,  7.0713e-02, -1.6410e-02, -4.3051e-02]],\n",
      "\n",
      "         [[-5.2802e-02, -4.8843e-02, -4.3820e-02, -9.7881e-03, -7.4137e-02],\n",
      "          [ 4.5320e-02, -5.3278e-02, -7.7669e-02, -3.9955e-02,  3.9849e-02],\n",
      "          [ 3.4464e-02,  3.9252e-03,  2.8187e-02,  7.6727e-02, -6.3247e-02],\n",
      "          [-1.0578e-02,  1.1429e-02, -7.5005e-02, -4.3371e-02, -6.2838e-02],\n",
      "          [-5.6429e-02,  5.3450e-02,  4.1316e-02,  4.2714e-02, -3.8975e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.7297e-02,  1.3228e-02, -3.9658e-02,  5.0158e-02,  6.4891e-02],\n",
      "          [-2.0991e-02,  4.7239e-02, -9.1070e-03,  6.9951e-02, -5.8856e-02],\n",
      "          [ 4.5112e-02,  7.6495e-04, -5.6494e-02, -7.9534e-02, -2.0190e-02],\n",
      "          [-2.7143e-02,  7.6870e-02, -8.5578e-04,  7.4763e-02,  3.1903e-02],\n",
      "          [-2.9161e-02, -2.7066e-02,  1.4447e-02, -5.2456e-02,  6.9604e-02]],\n",
      "\n",
      "         [[-3.6249e-02, -5.2929e-02,  6.3422e-02, -7.6986e-02,  1.8539e-02],\n",
      "          [-1.8349e-02, -4.5495e-02, -6.8062e-02, -6.5433e-03,  3.6338e-02],\n",
      "          [ 7.8693e-02, -1.7059e-02,  5.0849e-02, -7.1470e-02,  7.0145e-02],\n",
      "          [ 2.6199e-02,  8.0250e-02,  5.6080e-02, -1.6314e-02,  7.4349e-03],\n",
      "          [-2.5818e-02,  1.3434e-02,  3.6144e-02, -3.7618e-02,  1.9678e-02]],\n",
      "\n",
      "         [[ 5.8131e-02, -1.8722e-02, -1.7018e-02,  4.4221e-02,  7.2009e-02],\n",
      "          [ 7.0571e-02, -6.6096e-02, -2.6058e-02, -4.5113e-02,  4.2898e-02],\n",
      "          [ 2.7158e-02,  6.5821e-02, -1.9683e-02,  9.6510e-03, -5.8843e-02],\n",
      "          [ 3.8775e-02, -8.1913e-03,  7.7810e-02, -5.8010e-02, -6.7629e-02],\n",
      "          [ 1.5830e-02, -4.3622e-02,  2.2862e-02, -4.4371e-02,  4.9245e-02]],\n",
      "\n",
      "         [[ 5.2280e-02, -6.8192e-03,  3.6900e-02,  3.9519e-02, -6.8166e-02],\n",
      "          [-2.5690e-02,  7.3908e-02,  3.4166e-02,  1.0524e-02, -2.5315e-02],\n",
      "          [ 7.0046e-03,  7.9610e-02, -4.9690e-02, -6.0950e-02, -7.5060e-02],\n",
      "          [-2.5601e-02, -2.6599e-02,  1.2605e-02,  4.2499e-02, -6.1939e-02],\n",
      "          [-6.1473e-02,  4.9146e-02,  5.0904e-02,  6.9609e-02,  7.7738e-02]],\n",
      "\n",
      "         [[ 7.6798e-02,  1.8800e-02, -9.0222e-03, -6.3031e-02,  3.1588e-02],\n",
      "          [ 7.9743e-02, -7.4606e-02, -4.9082e-02, -2.7467e-02,  6.9497e-02],\n",
      "          [-4.1262e-02,  3.3714e-03,  7.9555e-02,  6.2146e-02, -3.7076e-02],\n",
      "          [-5.0311e-02,  6.1257e-02,  9.9275e-03,  3.3976e-02,  4.4057e-02],\n",
      "          [ 6.1631e-02, -2.0539e-03, -7.3543e-02,  2.3530e-02,  2.3014e-02]],\n",
      "\n",
      "         [[-6.5634e-02, -5.4410e-02,  5.5005e-02,  6.7584e-02, -4.9105e-02],\n",
      "          [-1.2715e-02,  2.9877e-02,  8.4349e-03, -6.6563e-02,  5.4926e-02],\n",
      "          [-1.6380e-02,  5.0518e-02,  4.0936e-02,  7.5998e-02,  5.6260e-02],\n",
      "          [ 8.0564e-02, -5.4198e-03,  4.1809e-02, -5.1103e-02, -1.3125e-02],\n",
      "          [ 6.7262e-02, -2.1399e-02, -2.2313e-02, -4.6630e-02,  3.2639e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6907e-02,  7.2977e-02, -5.6491e-02, -5.8080e-02, -3.5910e-02],\n",
      "          [-4.7978e-02, -6.3164e-02,  6.2754e-03, -6.2500e-02,  5.7852e-02],\n",
      "          [-2.4682e-02,  4.9645e-02, -5.3690e-02, -4.4223e-02, -7.0763e-02],\n",
      "          [ 7.9824e-02, -1.4418e-02,  1.2935e-02,  2.6139e-02,  3.9971e-02],\n",
      "          [-1.8336e-02,  2.5674e-02,  6.0938e-02, -5.4246e-03,  9.1462e-04]],\n",
      "\n",
      "         [[ 7.7591e-02,  2.2375e-02,  6.5237e-02, -5.2698e-02,  2.3875e-02],\n",
      "          [-4.7017e-02,  2.0042e-02,  2.1284e-02, -6.7296e-02, -3.1960e-02],\n",
      "          [ 5.9548e-02, -5.2732e-02,  6.3072e-03, -5.5593e-02, -3.2303e-02],\n",
      "          [ 1.4744e-02, -5.7092e-02, -4.1746e-02,  2.6749e-02,  1.6788e-02],\n",
      "          [-6.9063e-02, -8.1097e-02,  3.4484e-02,  2.4497e-02, -2.2169e-03]],\n",
      "\n",
      "         [[ 7.4762e-03, -3.6288e-02, -3.0510e-02,  6.9168e-02, -7.9159e-02],\n",
      "          [ 7.6720e-02,  1.9784e-02,  6.3913e-02,  3.5189e-02, -6.9533e-02],\n",
      "          [ 6.5572e-02,  3.0690e-02, -3.6841e-03,  7.9462e-02,  6.4771e-02],\n",
      "          [-3.4010e-02,  3.0556e-02,  7.6601e-02,  1.7668e-02, -3.6466e-02],\n",
      "          [ 3.4062e-02,  7.6049e-02,  7.7389e-02,  4.1314e-03,  3.5436e-02]],\n",
      "\n",
      "         [[ 7.3379e-02,  8.4377e-04, -5.2209e-02,  3.9102e-02, -1.7834e-02],\n",
      "          [-4.8015e-03,  7.5417e-02,  6.0744e-02, -3.9959e-02,  1.6464e-02],\n",
      "          [-2.1619e-02, -3.4922e-02,  2.4632e-02, -1.1665e-02, -6.9769e-02],\n",
      "          [-8.1614e-02,  7.7186e-02,  4.0543e-02, -3.7752e-03, -7.0552e-03],\n",
      "          [-4.7913e-02,  2.5675e-02,  5.2166e-02, -2.2791e-02,  7.6181e-02]],\n",
      "\n",
      "         [[-1.6448e-02, -2.9302e-02, -2.8030e-02, -5.1219e-02, -7.9234e-02],\n",
      "          [-4.1988e-03,  3.8661e-02, -4.9742e-02, -5.9553e-02,  8.1401e-02],\n",
      "          [ 4.2136e-02,  5.9677e-02,  7.7904e-03,  6.8196e-02, -4.6525e-02],\n",
      "          [ 3.0167e-02, -2.0376e-02,  2.0808e-02,  1.8796e-02,  3.1632e-02],\n",
      "          [-2.4592e-02,  3.0097e-02,  1.7232e-02,  7.7507e-02, -7.0299e-02]],\n",
      "\n",
      "         [[-2.2379e-02, -3.5771e-02,  7.8989e-02,  1.7590e-02,  3.9095e-03],\n",
      "          [-2.1773e-03, -5.6147e-02, -3.6993e-02, -4.6810e-02,  8.0930e-03],\n",
      "          [-1.9212e-02, -3.0507e-03,  2.9717e-02, -2.3541e-02, -3.2768e-02],\n",
      "          [ 1.1153e-02,  1.8848e-02, -1.6346e-02, -6.9419e-02, -5.1839e-02],\n",
      "          [ 4.6714e-03, -8.0722e-02,  7.7889e-02,  1.3596e-02, -2.1055e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.1160e-02, -6.2855e-02,  6.1618e-02,  4.5070e-02, -2.5824e-02],\n",
      "          [-3.9725e-02, -3.0585e-02, -3.6808e-02,  6.1494e-02,  8.2178e-03],\n",
      "          [ 4.3787e-02, -5.3779e-02, -6.9276e-02,  2.4147e-02,  4.8705e-02],\n",
      "          [-4.2152e-02, -4.2116e-02, -3.7383e-02,  7.2394e-02,  1.6059e-02],\n",
      "          [-7.3838e-02, -7.4526e-02,  6.1619e-02,  1.3842e-02,  7.5723e-02]],\n",
      "\n",
      "         [[ 7.5243e-03, -7.9138e-02, -4.1337e-02, -4.0382e-02, -1.0076e-02],\n",
      "          [ 7.1954e-02, -3.8210e-02, -7.6424e-02,  2.6636e-02,  5.7632e-02],\n",
      "          [-5.2085e-02,  4.3525e-02,  7.2752e-02,  7.6026e-02, -6.1516e-02],\n",
      "          [ 1.8230e-02, -2.0331e-02,  1.5863e-03, -1.5889e-02, -1.7665e-02],\n",
      "          [-7.5181e-02, -6.1528e-02,  6.5644e-02, -1.5125e-02, -1.2348e-02]],\n",
      "\n",
      "         [[ 6.7622e-02, -4.4414e-02, -2.7551e-02,  1.2861e-02,  2.1975e-02],\n",
      "          [-3.4223e-03, -1.7661e-02,  4.9568e-02, -2.8375e-02, -2.0616e-02],\n",
      "          [ 8.1921e-03, -7.8983e-02, -4.2053e-02,  1.5920e-02,  7.9573e-02],\n",
      "          [ 6.6158e-02,  5.8960e-02,  5.7813e-02, -1.8083e-02, -5.0136e-02],\n",
      "          [-2.7597e-02, -5.8831e-02, -9.8671e-03,  2.7747e-02,  6.1592e-02]],\n",
      "\n",
      "         [[-4.7195e-02,  5.7196e-02, -4.7626e-02,  3.9305e-02,  5.9069e-02],\n",
      "          [ 6.2709e-02,  3.8375e-02, -1.3523e-03, -2.9494e-02,  3.6191e-02],\n",
      "          [-5.0497e-02,  1.4287e-02,  3.6558e-02,  7.0254e-02, -7.4575e-02],\n",
      "          [-3.0616e-02, -6.3667e-02, -4.2500e-02, -5.5627e-02, -5.7194e-02],\n",
      "          [ 7.9488e-02, -4.2437e-02,  1.8161e-02,  6.4243e-02,  3.6040e-02]],\n",
      "\n",
      "         [[ 7.9697e-02, -3.1566e-02, -5.4912e-02,  2.7871e-02, -3.5522e-02],\n",
      "          [ 2.0966e-02, -6.8159e-02,  4.5011e-02, -2.3789e-02,  5.7085e-02],\n",
      "          [ 7.9964e-02, -3.3707e-02,  3.7487e-02,  6.8267e-02, -2.9291e-02],\n",
      "          [-4.0987e-02, -4.5809e-02, -7.8049e-04,  5.7912e-02,  5.0208e-02],\n",
      "          [-5.9828e-05, -7.7650e-02, -5.4334e-02,  7.1646e-02,  7.2639e-03]],\n",
      "\n",
      "         [[ 7.6258e-03, -2.5299e-02,  6.8546e-02, -6.1082e-02, -2.1409e-02],\n",
      "          [ 6.3198e-02,  3.4252e-03,  5.8270e-02,  4.3756e-02,  4.0571e-02],\n",
      "          [ 4.3608e-02, -3.5159e-02,  5.6774e-02, -2.3812e-02,  6.2682e-02],\n",
      "          [ 1.8924e-02,  4.5684e-03, -1.3125e-02, -5.7883e-02, -4.8575e-02],\n",
      "          [-5.1891e-02, -7.4029e-02, -5.5740e-02,  1.3945e-02, -5.5542e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.2934e-02,  5.6612e-03, -5.6791e-02,  6.7633e-02, -1.2613e-02],\n",
      "          [ 7.0192e-02, -7.3345e-02,  4.5917e-02, -6.9458e-02, -4.5503e-02],\n",
      "          [-3.5298e-02,  2.4038e-02, -6.2334e-02, -7.1980e-04,  3.7418e-02],\n",
      "          [-4.9582e-02,  3.9477e-03, -3.2252e-02,  3.9055e-03,  4.2763e-02],\n",
      "          [-4.9334e-02, -1.0912e-02, -7.6285e-02, -6.2953e-02, -2.1550e-02]],\n",
      "\n",
      "         [[ 4.5192e-02,  6.5101e-02, -2.1783e-02,  8.0309e-02, -5.0061e-02],\n",
      "          [-2.4252e-03,  2.6790e-02, -1.5355e-02, -3.8168e-02,  3.2681e-02],\n",
      "          [ 6.1128e-02,  4.7594e-02, -1.0053e-02,  6.0829e-02, -4.9079e-02],\n",
      "          [-2.1913e-02, -2.2059e-02,  6.0167e-02,  4.2953e-02,  3.2336e-02],\n",
      "          [ 4.8883e-02,  3.0470e-02, -5.8205e-03,  5.4365e-02,  6.8586e-02]],\n",
      "\n",
      "         [[ 3.4577e-03, -5.6117e-03,  8.0770e-02, -5.5850e-02, -8.0809e-02],\n",
      "          [-2.1647e-02, -6.3489e-03, -3.1593e-02, -9.4556e-03, -7.0688e-02],\n",
      "          [-7.7235e-02, -9.6896e-03,  7.1641e-02, -8.0411e-02,  2.6822e-02],\n",
      "          [-1.2272e-02,  1.0481e-02,  2.8910e-02,  1.3142e-02,  9.0787e-03],\n",
      "          [ 5.7873e-02, -3.3836e-03,  7.6251e-02,  6.5221e-02,  6.0223e-03]],\n",
      "\n",
      "         [[ 6.0748e-02, -3.0008e-02, -1.6359e-02, -1.0153e-02,  4.3994e-02],\n",
      "          [-5.7445e-03,  5.6531e-02,  6.2734e-02, -7.4414e-02,  1.1533e-02],\n",
      "          [ 5.2612e-02, -1.2373e-02, -3.0973e-02, -1.7253e-02, -6.0851e-03],\n",
      "          [-6.9136e-02,  6.3936e-02, -5.7642e-02, -2.3477e-02, -3.1410e-02],\n",
      "          [ 2.1037e-03,  2.3554e-02,  3.1823e-02, -6.1857e-02, -1.4312e-02]],\n",
      "\n",
      "         [[ 1.9664e-02,  5.7513e-02,  6.5881e-02,  4.4928e-02,  1.5795e-02],\n",
      "          [ 6.4092e-02, -6.9029e-02, -6.3861e-02,  2.6863e-02,  3.7089e-02],\n",
      "          [ 5.3542e-02,  7.6119e-02, -2.2586e-03,  7.1516e-02, -4.0801e-02],\n",
      "          [-5.8745e-02, -7.0054e-02, -5.0445e-02, -7.5631e-02,  5.2317e-02],\n",
      "          [-5.9762e-02, -3.3124e-02, -6.0695e-02,  5.8704e-02, -4.4235e-03]],\n",
      "\n",
      "         [[-7.8778e-02,  6.5156e-02, -5.1670e-02,  3.4715e-02,  7.6745e-02],\n",
      "          [-4.8319e-02, -8.1035e-02, -5.7326e-02, -3.1730e-02, -4.1259e-02],\n",
      "          [-6.0968e-02, -5.9338e-02,  1.3652e-02, -3.0278e-02,  1.1487e-02],\n",
      "          [-3.5814e-02, -2.2741e-02, -6.8842e-02,  2.3708e-02, -5.1073e-02],\n",
      "          [ 3.8621e-02, -3.0430e-02,  7.9626e-02,  4.9538e-02, -3.7956e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.5756e-03,  2.2459e-02, -3.5427e-02, -7.1947e-02,  7.0504e-02],\n",
      "          [ 4.1446e-02, -6.0459e-02, -2.6579e-02,  5.0985e-02,  6.9211e-02],\n",
      "          [ 2.2988e-02,  1.0344e-02, -3.8458e-02, -3.8696e-02, -4.7383e-02],\n",
      "          [-2.7025e-02,  5.3704e-02, -4.4350e-02,  5.1207e-02,  7.6981e-02],\n",
      "          [-2.2843e-02,  7.1587e-02,  2.8581e-02,  1.4226e-03,  4.3447e-03]],\n",
      "\n",
      "         [[-1.6005e-02,  5.0094e-03, -3.2745e-02,  6.2893e-02,  7.6595e-02],\n",
      "          [ 5.9817e-02,  3.0410e-02,  2.0731e-02,  5.2075e-02,  5.5742e-02],\n",
      "          [-2.2102e-02, -2.9947e-02,  1.5635e-02,  6.5275e-03, -2.7091e-02],\n",
      "          [ 4.5489e-04, -6.9148e-02,  2.2002e-02, -4.7160e-02, -4.9698e-02],\n",
      "          [ 3.4516e-02, -8.0964e-02,  7.3290e-02, -8.7487e-03,  5.9020e-02]],\n",
      "\n",
      "         [[-3.4915e-02, -7.1669e-02, -7.5109e-02,  4.5860e-02,  5.6023e-03],\n",
      "          [ 4.7610e-03,  1.0978e-02,  3.9942e-02, -8.1452e-02, -3.5630e-02],\n",
      "          [ 3.9804e-02, -7.7811e-02, -3.3754e-02,  7.9191e-02,  4.4801e-02],\n",
      "          [ 1.9758e-02,  2.2835e-02,  7.6000e-02,  3.5596e-03,  4.2032e-02],\n",
      "          [ 3.0850e-02,  3.5699e-02, -1.6856e-02, -4.3140e-02, -6.5399e-03]],\n",
      "\n",
      "         [[ 4.0406e-02,  4.7200e-02, -2.2973e-02, -8.1260e-02,  6.9188e-02],\n",
      "          [-4.9688e-02,  3.4393e-02,  3.6533e-02, -6.8810e-02,  4.7822e-02],\n",
      "          [ 3.9327e-02,  5.3709e-02,  4.8547e-02, -7.9277e-02,  4.0952e-02],\n",
      "          [-6.4483e-02, -6.3542e-02, -8.0647e-02,  7.7786e-02,  3.5994e-02],\n",
      "          [ 2.5992e-02,  3.5169e-02,  5.5619e-02,  4.8495e-02, -1.1145e-02]],\n",
      "\n",
      "         [[-1.4887e-02, -8.1387e-03,  7.6316e-02,  6.7959e-02, -1.4558e-02],\n",
      "          [ 1.7684e-02, -6.9868e-02, -6.0735e-02, -2.1803e-02, -5.5558e-02],\n",
      "          [-3.2864e-02, -5.6523e-02,  2.5162e-02, -5.8069e-02,  1.2625e-02],\n",
      "          [-9.0401e-03,  1.4308e-02, -2.3004e-02,  1.2891e-02, -4.8464e-02],\n",
      "          [ 6.2462e-02,  6.5198e-02,  3.4444e-02, -2.4303e-02, -5.5947e-02]],\n",
      "\n",
      "         [[-7.7466e-02, -7.7845e-02, -8.3282e-03,  2.2135e-02,  5.7583e-02],\n",
      "          [ 4.0174e-02, -3.8138e-02, -7.7990e-02, -1.1641e-02, -5.4870e-03],\n",
      "          [ 6.8281e-02,  6.6564e-02, -1.4003e-04,  7.4434e-03, -7.7141e-02],\n",
      "          [ 6.6704e-02, -3.5632e-03,  3.5503e-02,  2.6854e-02,  2.4533e-02],\n",
      "          [ 5.3770e-02,  7.2017e-02, -7.8339e-02,  2.6578e-02,  5.3753e-02]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0098, -0.0741, -0.0191, -0.0294, -0.0688, -0.0039, -0.0036, -0.0177,\n",
      "        -0.0750,  0.0117,  0.0277, -0.0044, -0.0381, -0.0392,  0.0627,  0.0210],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0178, -0.0067, -0.0364,  ...,  0.0126,  0.0097, -0.0317],\n",
      "        [-0.0001, -0.0448, -0.0205,  ...,  0.0468,  0.0347, -0.0128],\n",
      "        [-0.0180, -0.0181, -0.0389,  ...,  0.0390,  0.0439,  0.0285],\n",
      "        ...,\n",
      "        [-0.0352, -0.0031, -0.0172,  ..., -0.0454,  0.0047, -0.0483],\n",
      "        [ 0.0281, -0.0060,  0.0028,  ...,  0.0347, -0.0243,  0.0071],\n",
      "        [ 0.0162, -0.0068,  0.0499,  ...,  0.0317, -0.0299,  0.0166]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0200, -0.0267, -0.0063,  0.0058, -0.0487,  0.0362,  0.0219, -0.0334,\n",
      "        -0.0444, -0.0483,  0.0042, -0.0297,  0.0128,  0.0370, -0.0042, -0.0411,\n",
      "        -0.0448, -0.0400,  0.0370,  0.0180,  0.0440,  0.0309, -0.0335, -0.0229,\n",
      "        -0.0211,  0.0373,  0.0377, -0.0210, -0.0170,  0.0400, -0.0081, -0.0224,\n",
      "        -0.0375, -0.0395, -0.0432, -0.0311, -0.0291,  0.0298,  0.0238, -0.0051,\n",
      "        -0.0233, -0.0140,  0.0479,  0.0434, -0.0453, -0.0159, -0.0268,  0.0401,\n",
      "        -0.0125, -0.0199,  0.0266, -0.0429,  0.0216,  0.0033,  0.0144,  0.0379,\n",
      "         0.0291, -0.0223, -0.0134, -0.0110, -0.0232,  0.0282, -0.0085, -0.0104,\n",
      "        -0.0310,  0.0011,  0.0164,  0.0156, -0.0317,  0.0024,  0.0127,  0.0211,\n",
      "         0.0329, -0.0002, -0.0306,  0.0124, -0.0430,  0.0212,  0.0323, -0.0235,\n",
      "        -0.0408,  0.0111, -0.0465, -0.0421,  0.0359, -0.0466,  0.0483, -0.0443,\n",
      "         0.0257,  0.0220, -0.0193,  0.0171,  0.0456,  0.0360, -0.0488,  0.0345,\n",
      "        -0.0441,  0.0111, -0.0135, -0.0464,  0.0108,  0.0233, -0.0216, -0.0335,\n",
      "        -0.0302, -0.0129, -0.0034, -0.0478, -0.0374, -0.0194,  0.0094, -0.0221,\n",
      "         0.0008,  0.0083, -0.0446,  0.0243,  0.0379, -0.0436,  0.0448, -0.0015],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0838,  0.0075,  0.0868,  ...,  0.0424,  0.0046,  0.0462],\n",
      "        [ 0.0083,  0.0268, -0.0619,  ..., -0.0500,  0.0240,  0.0132],\n",
      "        [-0.0257, -0.0180,  0.0747,  ..., -0.0450, -0.0315, -0.0190],\n",
      "        ...,\n",
      "        [-0.0574, -0.0599, -0.0157,  ...,  0.0652,  0.0525,  0.0850],\n",
      "        [ 0.0242, -0.0417, -0.0511,  ...,  0.0518, -0.0028, -0.0504],\n",
      "        [ 0.0397, -0.0730, -0.0200,  ...,  0.0853,  0.0522,  0.0591]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0646,  0.0330,  0.0569,  0.0493, -0.0273,  0.0612,  0.0393,  0.0477,\n",
      "        -0.0871, -0.0418,  0.0849, -0.0260, -0.0338, -0.0527, -0.0023, -0.0693,\n",
      "         0.0572,  0.0746,  0.0003,  0.0675, -0.0530,  0.0564, -0.0761,  0.0691,\n",
      "        -0.0307,  0.0882, -0.0529,  0.0478, -0.0172, -0.0560,  0.0265,  0.0607,\n",
      "        -0.0361,  0.0739,  0.0681, -0.0441,  0.0731, -0.0604, -0.0692,  0.0409,\n",
      "         0.0870, -0.0249, -0.0108, -0.0069,  0.0518,  0.0822, -0.0706, -0.0448,\n",
      "         0.0421, -0.0667,  0.0563,  0.0280, -0.0650, -0.0073, -0.0683, -0.0293,\n",
      "        -0.0415,  0.0235,  0.0246,  0.0009,  0.0131,  0.0304, -0.0630,  0.0904,\n",
      "        -0.0407,  0.0497,  0.0414, -0.0398, -0.0356, -0.0366,  0.0341,  0.0774,\n",
      "         0.0098,  0.0183,  0.0737, -0.0121,  0.0705,  0.0422,  0.0306,  0.0662,\n",
      "         0.0755,  0.0059, -0.0393,  0.0718], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 7.3794e-02,  1.5620e-02, -6.4877e-03,  4.0250e-02,  5.3988e-03,\n",
      "          1.0297e-01, -1.7401e-02, -1.1827e-02,  1.0808e-01,  4.4128e-02,\n",
      "         -2.4649e-02,  1.0782e-01, -6.1297e-02,  6.4179e-02, -6.3155e-02,\n",
      "          5.5992e-02,  7.4418e-02,  7.7945e-02,  1.3729e-02,  7.1429e-02,\n",
      "         -4.3070e-02,  6.3338e-02, -1.4654e-02, -2.8125e-02,  6.7265e-02,\n",
      "          9.6300e-02,  1.5806e-03,  4.7477e-02, -8.2798e-02,  8.6989e-02,\n",
      "         -2.9238e-02,  8.2513e-03,  1.0255e-01, -3.2332e-03,  3.1421e-02,\n",
      "         -3.2587e-02,  3.6793e-02, -1.9082e-02,  1.0017e-01,  4.2111e-02,\n",
      "         -7.2117e-02, -1.0828e-01, -1.0873e-01,  7.8841e-02,  4.2129e-02,\n",
      "         -8.9661e-03,  3.3923e-02,  1.0437e-01,  9.8393e-03, -7.5443e-02,\n",
      "         -4.6820e-02, -7.5324e-02, -6.2734e-02,  5.3724e-02, -1.1000e-02,\n",
      "         -6.5400e-02,  4.7437e-02, -3.9302e-02,  2.7017e-02, -4.9362e-02,\n",
      "          2.1495e-02,  1.5443e-02, -1.4647e-02, -8.3732e-02, -2.7405e-02,\n",
      "          8.7514e-02,  1.0705e-01, -1.4984e-02, -1.6917e-02,  1.4212e-03,\n",
      "         -4.7650e-02,  8.6882e-02, -9.4222e-02, -8.8289e-02,  7.6620e-02,\n",
      "          9.1884e-02, -8.2335e-02,  1.0170e-01, -1.0383e-01, -7.6452e-02,\n",
      "          3.6703e-02,  1.0829e-01,  5.0116e-02,  4.9381e-02],\n",
      "        [-5.4742e-03,  1.4955e-02, -6.4130e-02,  7.6739e-02, -6.6693e-02,\n",
      "          2.9079e-02, -9.1313e-02,  2.1001e-02, -2.1549e-02, -1.0476e-02,\n",
      "         -9.9883e-02, -6.7783e-02, -9.4817e-02,  2.1995e-02, -3.6486e-02,\n",
      "          4.9724e-02, -1.0884e-01, -6.5711e-02,  5.7294e-02,  9.8684e-02,\n",
      "          3.5132e-02, -5.3354e-02,  3.9116e-02,  2.6113e-02, -7.2787e-02,\n",
      "         -9.6649e-02,  2.4468e-05, -4.7067e-02, -1.0107e-01,  6.3852e-02,\n",
      "          4.9891e-02, -1.2634e-02,  6.5477e-02,  2.8010e-02, -6.6948e-03,\n",
      "         -7.6858e-02,  3.8545e-02,  4.8159e-02, -4.5223e-03, -4.9237e-02,\n",
      "          1.6163e-02,  9.5864e-02, -7.3326e-02,  2.5793e-02,  1.4653e-02,\n",
      "         -9.5057e-02,  4.6607e-02,  8.1657e-02,  8.4285e-02,  3.0182e-02,\n",
      "         -8.6617e-02, -7.9096e-02, -9.8373e-02, -4.0375e-02, -4.9808e-02,\n",
      "         -7.9870e-02,  5.6966e-02, -6.2504e-02,  9.2422e-02, -6.6717e-02,\n",
      "          7.6754e-02, -2.8715e-02, -5.7317e-02,  5.3053e-02, -1.0298e-01,\n",
      "         -8.9620e-02, -1.5274e-02, -1.0073e-01, -1.8519e-02, -6.0857e-02,\n",
      "         -1.9620e-02,  6.4661e-02, -9.0501e-02, -1.4954e-04, -8.2876e-02,\n",
      "         -7.7159e-02,  1.0485e-01, -2.0678e-02,  8.7149e-03, -5.5858e-03,\n",
      "          9.5727e-02,  7.0501e-02,  9.8033e-02,  6.5686e-02],\n",
      "        [ 3.0216e-02,  5.0019e-02,  9.6151e-02,  1.0151e-01,  2.6510e-02,\n",
      "          6.4569e-02, -1.0446e-01, -6.7226e-02,  6.5618e-02, -2.9354e-02,\n",
      "          8.3451e-02, -5.9400e-02,  2.6738e-02,  9.5954e-02,  1.0252e-01,\n",
      "         -5.7567e-02,  9.6787e-02, -8.4892e-02, -4.1802e-02, -1.1358e-02,\n",
      "          1.0125e-01,  4.3689e-03,  9.4880e-03, -9.7126e-03,  3.2395e-02,\n",
      "         -7.5122e-02, -6.8766e-02, -6.1825e-02,  9.6442e-02, -9.4918e-02,\n",
      "          7.8926e-02, -3.5376e-02,  2.8081e-03,  8.9178e-02,  7.9882e-02,\n",
      "         -4.9176e-02, -7.7379e-02,  2.8729e-02,  5.6048e-02,  3.7434e-02,\n",
      "         -5.1131e-02,  9.7410e-02, -9.2568e-02,  2.9076e-02,  4.7677e-02,\n",
      "          2.6594e-02, -2.1058e-02,  9.0663e-02,  6.3638e-03, -9.7866e-03,\n",
      "         -2.4411e-02, -1.0087e-01,  1.0770e-01, -9.3060e-02,  6.5705e-02,\n",
      "          7.1363e-02,  6.8090e-02, -1.3437e-02, -7.2885e-02,  6.7369e-02,\n",
      "         -8.4491e-02, -4.1715e-02, -9.5944e-02,  5.5469e-03,  3.9267e-02,\n",
      "          9.3484e-02,  4.9953e-02, -7.5840e-02,  9.3084e-02,  4.2249e-02,\n",
      "         -8.1323e-02, -1.9922e-02,  8.6720e-02,  9.7163e-02, -7.3905e-03,\n",
      "         -4.1507e-02,  6.7719e-02,  5.9078e-02,  2.1743e-02, -3.5342e-02,\n",
      "         -2.1192e-02, -5.1317e-02,  7.0349e-02, -4.1888e-02],\n",
      "        [ 1.1912e-02, -6.5012e-02,  5.5201e-02,  5.3485e-02, -5.9837e-03,\n",
      "          5.2693e-02, -4.5141e-02,  9.5898e-02,  8.6545e-02,  4.6896e-02,\n",
      "         -3.3529e-02, -2.5136e-02,  4.6092e-02,  1.0858e-01, -1.0701e-01,\n",
      "          3.2039e-02, -5.1970e-02, -4.7014e-02, -4.2324e-02,  8.3037e-02,\n",
      "          6.0433e-02, -8.3411e-02, -3.1766e-02, -4.1621e-02, -5.4987e-02,\n",
      "          6.5951e-02, -1.9566e-02,  8.2347e-02, -2.7276e-02, -5.5290e-03,\n",
      "         -2.6687e-02, -1.3273e-02, -3.1139e-02, -8.9573e-02, -5.6785e-02,\n",
      "          9.1472e-02,  3.2392e-03,  1.5634e-03, -8.6058e-02, -9.5225e-02,\n",
      "         -3.6599e-03,  5.7188e-02, -2.5975e-02,  9.9359e-02, -8.9290e-02,\n",
      "          5.4974e-02, -3.3053e-02,  5.8862e-02,  2.3305e-02, -2.4918e-02,\n",
      "         -2.9802e-07, -4.4170e-02,  8.8485e-02, -1.9346e-02,  7.1999e-02,\n",
      "         -8.2179e-02,  1.0618e-02,  8.3245e-02, -6.3851e-02, -4.5822e-02,\n",
      "          7.9047e-02, -5.0467e-02,  5.1076e-02, -1.0634e-01,  9.2872e-02,\n",
      "         -1.0846e-01, -1.0122e-01,  2.3580e-02, -4.3849e-03,  8.6141e-02,\n",
      "          7.5211e-02,  1.8899e-02, -6.8921e-02,  6.9561e-02, -2.3550e-02,\n",
      "          1.6788e-02,  8.6251e-03, -7.5976e-02, -6.5675e-02, -9.2606e-02,\n",
      "          5.4780e-02,  3.2605e-03, -4.3780e-02, -2.2522e-02],\n",
      "        [-1.0697e-01,  4.8336e-02,  6.5768e-02,  2.6546e-02, -1.1699e-02,\n",
      "         -4.5614e-02,  9.6034e-02,  5.1094e-02,  5.4941e-02, -1.0205e-01,\n",
      "         -1.8846e-02, -2.4748e-02, -3.2494e-02,  6.1650e-02,  9.6738e-02,\n",
      "          8.4908e-02, -4.3878e-02, -9.5392e-02,  9.8040e-02, -3.1203e-02,\n",
      "          6.9738e-02, -9.4117e-02,  1.2433e-03, -2.3340e-02, -7.5392e-02,\n",
      "          4.7267e-02, -9.7156e-02, -4.2846e-02, -6.5548e-02,  6.6793e-02,\n",
      "         -4.2942e-02, -5.5622e-02,  3.3243e-02,  1.0791e-01,  8.7332e-02,\n",
      "          3.8399e-02,  9.2853e-02, -7.2801e-02,  1.0720e-01,  8.5661e-02,\n",
      "          1.0466e-01, -6.1025e-02, -3.3746e-02,  6.8673e-02, -5.1211e-02,\n",
      "         -4.1191e-02,  9.4379e-02,  4.0398e-02,  9.6810e-02, -1.0040e-01,\n",
      "          1.0349e-01, -8.9425e-02,  7.8313e-02, -6.8106e-02,  8.3556e-02,\n",
      "          4.2241e-02, -4.4091e-02, -4.1653e-03,  3.2682e-03, -3.0460e-02,\n",
      "         -1.5077e-02, -9.6863e-02, -2.3551e-02, -7.6818e-02, -1.9592e-02,\n",
      "          3.6177e-02, -4.4923e-02, -4.1503e-02,  1.0435e-01, -4.1457e-02,\n",
      "         -4.3890e-02, -5.8244e-02, -5.3735e-02, -9.4220e-02,  7.7722e-02,\n",
      "         -3.3392e-02,  8.0107e-02, -4.4418e-02, -5.8001e-02,  6.3878e-02,\n",
      "         -9.8351e-02, -9.3931e-02, -3.1695e-02, -8.0684e-02],\n",
      "        [-3.1888e-02,  9.6571e-02, -1.0552e-01, -1.0178e-01,  1.8233e-02,\n",
      "         -7.1853e-02,  2.7176e-02,  8.8741e-02, -2.1809e-02,  2.3507e-02,\n",
      "         -2.2871e-02,  6.8581e-02,  1.0457e-01, -9.8167e-02, -5.2392e-02,\n",
      "          5.9442e-02, -9.6549e-02,  9.7735e-02,  5.2298e-02, -9.0279e-02,\n",
      "          1.0329e-01, -8.7093e-03, -5.6421e-02,  3.6799e-02,  9.7930e-02,\n",
      "          8.8452e-02,  9.4982e-02,  1.0604e-01, -3.0680e-02, -1.0470e-01,\n",
      "          5.5976e-02,  1.0827e-01,  3.9787e-02, -7.1503e-02,  1.0691e-01,\n",
      "         -4.4232e-02, -7.6271e-02,  7.7432e-02, -3.5097e-02,  1.8720e-02,\n",
      "          6.2259e-02, -7.9610e-02,  8.3630e-02, -4.0665e-03,  8.8457e-02,\n",
      "          4.3148e-02, -7.2924e-02, -9.6653e-02,  3.8939e-02, -8.2061e-02,\n",
      "          5.3569e-02, -7.0598e-02, -3.0911e-02, -6.8275e-02, -6.4321e-02,\n",
      "         -1.6644e-04, -1.8860e-02, -8.0424e-02,  2.8854e-02, -5.6870e-02,\n",
      "         -4.8995e-02, -6.3335e-02,  1.6464e-02, -7.8274e-02,  4.3533e-02,\n",
      "          3.0335e-02,  1.5449e-02, -3.3745e-02, -3.1853e-02, -6.9549e-02,\n",
      "         -1.0569e-01, -1.0508e-01, -1.4948e-02,  1.0554e-02,  1.9330e-02,\n",
      "          1.2147e-02, -8.1693e-02,  4.1709e-02, -8.6101e-02,  8.1133e-02,\n",
      "         -5.2590e-02, -2.6211e-02,  2.9723e-02,  6.7879e-02],\n",
      "        [ 6.5213e-02, -8.4256e-02, -8.5273e-02, -6.0963e-02, -7.9917e-02,\n",
      "          8.0582e-02,  4.0738e-02, -6.6151e-02,  1.0097e-01,  6.7800e-02,\n",
      "          7.7926e-02,  5.1981e-02,  7.6131e-02, -8.5172e-02,  3.7479e-03,\n",
      "          1.0677e-01, -7.4097e-02,  5.8515e-03, -5.4686e-02,  6.2665e-02,\n",
      "         -4.0069e-02, -1.4017e-02, -9.6497e-02, -2.7905e-02,  1.5289e-02,\n",
      "          5.0492e-02, -3.9716e-02,  2.0026e-02,  2.7201e-02,  4.1062e-02,\n",
      "          1.0097e-01, -4.4331e-02, -6.8679e-02, -1.8584e-02,  1.0821e-01,\n",
      "         -9.4917e-03,  5.0698e-02, -7.9688e-03,  5.6621e-03, -3.1491e-02,\n",
      "         -1.3346e-02,  1.0586e-01,  6.8385e-02,  7.2201e-02,  7.4441e-02,\n",
      "          9.1421e-02, -6.6213e-03, -8.8222e-02,  8.3971e-02, -6.9101e-02,\n",
      "          1.7105e-02,  1.0829e-01,  7.7092e-02, -1.2912e-02,  5.4567e-02,\n",
      "         -1.0292e-01, -7.7125e-02, -8.7941e-02, -7.8538e-02,  9.1254e-02,\n",
      "         -9.5106e-02,  1.5189e-02,  2.0986e-02,  5.7309e-02, -2.1262e-02,\n",
      "          5.4266e-03, -5.3621e-02, -2.1693e-02, -2.8722e-02,  2.8545e-02,\n",
      "         -1.0842e-01,  8.9060e-02, -1.7672e-02, -1.0028e-01, -4.9354e-02,\n",
      "         -3.1612e-02,  4.0722e-02,  1.0809e-01,  6.5782e-03,  5.9725e-02,\n",
      "         -2.6836e-03, -2.7254e-02, -8.6179e-04,  5.2915e-02],\n",
      "        [-9.8945e-02,  8.0345e-02,  3.3181e-02,  4.4514e-02, -5.5221e-03,\n",
      "         -9.9729e-02, -3.4561e-02,  9.7025e-02,  8.3708e-02, -5.4137e-02,\n",
      "         -1.0708e-01,  6.8836e-02,  8.2482e-02, -6.9885e-02,  1.0584e-02,\n",
      "          6.9942e-02,  1.0492e-01,  4.6924e-02,  7.0377e-02, -4.4008e-02,\n",
      "          2.5684e-02, -5.4459e-02,  4.6665e-02, -2.1340e-02,  3.0847e-03,\n",
      "         -5.3649e-02, -5.1318e-02,  4.2861e-02,  2.1643e-02, -1.6357e-02,\n",
      "         -8.0137e-02,  6.5160e-02, -6.4095e-02, -8.2644e-02, -4.6775e-02,\n",
      "          4.4345e-02, -2.1651e-02,  9.1377e-02, -4.8625e-03,  4.9521e-02,\n",
      "         -8.6246e-03,  1.0740e-01,  4.2112e-02,  7.2138e-03,  1.0522e-02,\n",
      "         -1.6022e-02, -8.9038e-02, -9.7887e-02, -3.5791e-02, -8.3321e-02,\n",
      "         -1.0466e-01, -1.6102e-02, -4.4841e-02, -4.8403e-02, -7.7857e-02,\n",
      "         -5.3166e-02, -2.7882e-02, -9.2002e-03,  3.8229e-02,  5.8142e-02,\n",
      "          1.9832e-02,  1.3218e-02, -7.1583e-02, -5.2425e-02,  3.6732e-02,\n",
      "         -2.0079e-02, -1.0020e-01, -4.7348e-02, -4.3084e-02,  5.9707e-02,\n",
      "          4.9717e-02, -9.3241e-02, -2.6396e-02,  9.5293e-02,  3.1941e-02,\n",
      "         -9.7171e-02,  8.9733e-03, -1.0684e-01, -1.0651e-01, -4.4667e-02,\n",
      "          1.1034e-02, -6.0813e-02,  7.3580e-02, -1.4047e-02],\n",
      "        [-6.7485e-02, -2.4712e-02, -4.8118e-02,  6.0948e-02, -8.8888e-02,\n",
      "          7.3246e-02,  4.6855e-02,  4.8799e-02, -9.0475e-03,  5.9991e-02,\n",
      "         -7.2457e-02, -4.7209e-02, -4.9120e-02,  4.0945e-02, -9.5152e-02,\n",
      "         -1.0807e-01,  4.4417e-02, -1.4142e-02, -9.5727e-02,  1.0797e-01,\n",
      "         -1.0592e-01, -1.0476e-01, -1.2432e-02, -3.0853e-02,  1.5055e-02,\n",
      "          2.2322e-02,  1.6448e-02, -6.9099e-02,  8.2327e-02,  8.8142e-02,\n",
      "          7.7917e-02,  5.9746e-02, -2.4297e-02, -8.2149e-02, -9.5534e-03,\n",
      "          4.8747e-02, -3.7620e-02,  8.1809e-02, -1.8827e-02, -8.2226e-02,\n",
      "          7.1300e-02, -1.0237e-01, -7.0006e-02, -6.5360e-02,  5.4848e-02,\n",
      "          1.4864e-02, -8.7680e-02, -6.5633e-02,  1.0091e-01,  1.0252e-02,\n",
      "         -9.6865e-02, -6.6929e-02, -9.8863e-02,  3.8236e-02,  2.9536e-02,\n",
      "         -1.1084e-02,  9.8488e-02, -5.0771e-02,  1.0337e-01,  1.3285e-02,\n",
      "         -8.2319e-02,  6.6462e-02,  2.3691e-02,  7.4991e-02, -3.7303e-02,\n",
      "          9.9053e-02,  6.1848e-02, -1.0499e-01,  5.9010e-02,  8.9641e-02,\n",
      "         -5.6227e-02,  1.6536e-02, -7.9248e-02,  2.4565e-02,  2.3499e-02,\n",
      "         -2.3356e-02,  1.0667e-02, -9.3576e-02,  3.2491e-02,  8.7927e-02,\n",
      "         -6.5785e-02, -7.7460e-02, -7.4488e-03, -5.1835e-02],\n",
      "        [ 5.5938e-02,  7.9995e-02, -1.1993e-02, -1.6152e-02, -2.8862e-02,\n",
      "          1.8970e-03, -4.7627e-02, -1.0438e-01,  8.4505e-02, -4.9622e-02,\n",
      "         -4.0114e-03, -6.4740e-02, -3.2591e-02, -8.8721e-02, -2.7248e-02,\n",
      "         -2.6774e-04,  1.0802e-01,  1.5677e-02,  1.0179e-01,  8.1922e-04,\n",
      "          7.5765e-02, -4.5379e-02, -6.7991e-02,  7.6286e-02,  1.4660e-02,\n",
      "         -8.9811e-02,  1.8782e-02,  4.1900e-02,  1.0429e-01, -7.8253e-02,\n",
      "          1.0463e-01,  5.9268e-03, -9.5941e-02,  7.9558e-02, -8.9152e-02,\n",
      "          3.0542e-02, -7.8967e-02,  7.4771e-02,  3.5401e-02, -5.6039e-03,\n",
      "          8.5928e-02,  7.6615e-03,  9.2185e-02,  1.3986e-02, -9.2396e-02,\n",
      "         -1.7579e-02,  1.6400e-02,  2.5388e-02,  8.2298e-02,  6.4955e-02,\n",
      "          4.3538e-02,  5.9320e-02, -9.1966e-03, -9.7019e-02, -8.5265e-02,\n",
      "          7.9196e-03,  9.5258e-02, -5.2991e-03, -2.6844e-02,  6.8858e-02,\n",
      "          6.2456e-02,  2.5518e-02,  2.0207e-02,  5.2167e-02,  1.4807e-02,\n",
      "          3.4822e-03,  1.0715e-02,  6.6255e-02,  9.0971e-02,  1.5329e-02,\n",
      "          2.8047e-02, -2.3864e-02, -7.7135e-02, -6.5678e-02,  2.0336e-02,\n",
      "          2.2125e-02, -1.4425e-02,  4.1100e-02,  1.4858e-02, -5.1186e-03,\n",
      "         -6.7352e-02, -4.5486e-02, -1.7684e-02, -6.3769e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0274,  0.0744,  0.0173,  0.0575,  0.0658,  0.0647,  0.0700, -0.0859,\n",
      "         0.0094,  0.0776], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in net.parameters():\n",
    "    print(i) #默认被初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name,\":\",parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward 函数的输入和输出都是Variabel，只有Variable才具有自动求导功能，所以在输入时，需要把Tensor封装为Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0413,  0.0177,  0.0695, -0.0254,  0.1251,  0.0619,  0.1362, -0.1597,\n",
       "          0.0007,  0.0918]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Variable(torch.randn(1,1,32,32))\n",
    "out = net(inputs)\n",
    "out.size()\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行反向传播，并将所有梯度清零"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在进行backward时，若out为标量时，不需要指定grad_tensors，而若out为tensor时，则需要制定，且grad_tensors的shape必须与out的相同，并将其设置为1，计算时为：grad_tensord*grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.ones(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：torch.nn只支持mini_bitches，每次输入必须为一个batch，若想只输入一个样本，则需要使用inputs.unsqueeze(0)，将batch_size设置为1。例如nn.Conv2d的输入必须为4维，且必须为batch_size*c*h*w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn实现了神经网络中绝大数的损失函数，例如，nn.MSELoss用来计算均方差误差，nn.CrossEntropyLoss用来计算交叉熵损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.range(0, 10) ----> tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 10.])\n",
    "torch.arange(0, 10) ---->tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.2236, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzx/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "out = net(inputs)\n",
    "target = Variable(torch.arange(0, 10.0))\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反向传播前的梯度： tensor([0., 0., 0., 0., 0., 0.])\n",
      "反向传播后的梯度： tensor([-0.0138,  0.1222,  0.0078,  0.0218,  0.0409,  0.0432])\n"
     ]
    }
   ],
   "source": [
    "# 运行backward，并观察参数梯度的变化情况\n",
    "net.zero_grad() #学习前将梯度清零\n",
    "print(\"反向传播前的梯度：\", net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print(\"反向传播后的梯度：\", net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "反向传播后会得到所有参数的梯度，还需要使用优化方法来更新网络参数。torch.optim中集成了绝大多数的优化方法，RMSProp,Adam和SGD等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#指定优化器，并指定要学习的参数和学习率\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "#训练过程中需要先将梯度清零\n",
    "optimizer.zero_grad() #与net.zero_grad()相同效果\n",
    "\n",
    "output = net(inputs)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "#更新参数\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像加载和与处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch中提供了常用的数据加载和处理功能。如Imagenet,CIFA10,MNIST等，以及常用的数据转换操作。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "580px",
    "left": "939px",
    "top": "111px",
    "width": "297px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
